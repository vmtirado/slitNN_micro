{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hello_world_split1.ipynb","provenance":[],"authorship_tag":"ABX9TyMLrmz3WQcWbZn+OO1UyziY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Split1\n","In this jupyter notebook we create the schema for the first split of the neural network. This network will have the input and the first hidden layer. After creating the schema we will load the weights corresponding to the first hidden layer to it. \n","After loading the weigths to the model we will export it to an unquantized version of tensorflowlite that will run in the first ESP32. "],"metadata":{"id":"yPBowfqGnlff"}},{"cell_type":"markdown","source":["## Mounting drive"],"metadata":{"id":"-lgadMo7pYqQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RrOqfqdDKK-W","executionInfo":{"status":"ok","timestamp":1651597720534,"user_tz":300,"elapsed":20783,"user":{"displayName":"Vilma Tirado Gómez","userId":"08135427317933817305"}},"outputId":"adeedcfc-f3e4-4c6d-f143-e131b636b4a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os \n","os.chdir(\"/content/drive/MyDrive/spiltNN/hello_world_esp32_split/\")\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Spwgh6wLzU2","executionInfo":{"status":"ok","timestamp":1651597727932,"user_tz":300,"elapsed":757,"user":{"displayName":"Vilma Tirado Gómez","userId":"08135427317933817305"}},"outputId":"41621719-b8f1-479b-fc2b-7c63d912d40d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["converted_model.tflite\t   hello_world_joined_split.ipynb  models\n","esp_split1\t\t   hello_world_model.h5\t\t   output_split.pickle\n","esp_split2\t\t   hello_world_split1.ipynb\t   x_test.pickle\n","hello_world_full_NN.ipynb  hello_world_split2.ipynb\n"]}]},{"cell_type":"code","source":["# TensorFlow is an open source machine learning library\n","import tensorflow as tf\n","\n","# Keras is TensorFlow's high-level API for deep learning\n","from tensorflow import keras\n","# Numpy is a math library\n","import numpy as np\n","# Pandas is a data manipulation library \n","import pandas as pd\n","# Matplotlib is a graphing library\n","import matplotlib.pyplot as plt\n","# Math is Python's math library\n","import math\n","\n","# Set seed for experiment reproducibility\n","seed = 1\n","np.random.seed(seed)\n","tf.random.set_seed(seed)"],"metadata":{"id":"X5L9nERcL9XZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create model schema\n","We create the model schema for the first split of the neural network. This is the first layer that has 16 neurons an a relu activation function. \n","For the model to be updated correctly the name of the layer in this schema must be the same as the one assigned to the layer in the full hello_world model. In this case the first hidden layer has the name `first_layer` in both models. "],"metadata":{"id":"M2lShHGENn8a"}},{"cell_type":"code","source":["split1_model = tf.keras.Sequential()\n","\n","# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n","# neurons decide whether to activate based on the 'relu' activation function.\n","split1_model.add(keras.layers.Dense(16, activation='relu', name=\"first_layer\", input_shape=(1,)))\n"],"metadata":{"id":"CyqxcYjLNp75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Upload weights\n","We upload the weights to the model we just created and check that the model parameters coincide with the ones of the full neural network. The parameter `by_name=True` ensures that the weights are uploaded to each layer properly. "],"metadata":{"id":"Ls2A1kgtT1HI"}},{"cell_type":"code","source":["split1_model.load_weights(\"hello_world_model.h5\", by_name=True)\n","split1_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYy74N04S-m-","executionInfo":{"status":"ok","timestamp":1651597755965,"user_tz":300,"elapsed":566,"user":{"displayName":"Vilma Tirado Gómez","userId":"08135427317933817305"}},"outputId":"231f3d79-d365-42c8-e28e-1d5e22e46ab4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," first_layer (Dense)         (None, 16)                32        \n","                                                                 \n","=================================================================\n","Total params: 32\n","Trainable params: 32\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Export model to tflite model \n","We quantize the model and then export it to tensoflow lite. The resulting file is a `.tflite` file, this file can be exported to a c++ file that contains the weights of the network. This file can be either quantized or not quantized\n","### Quantized\n"],"metadata":{"id":"ibmGxGof4vXD"}},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(split1_model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","def representative_dataset_gen():\n","    for _ in range(10000):\n","        yield [\n","            np.array(\n","                [np.random.uniform(), np.random.uniform()]\n","            , dtype=np.float32)\n","        ]\n","converter.representative_dataset = representative_dataset_gen\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","tflite_quant_model = converter.convert()\n","open(\"converted_model_split1.tflite\", \"wb\").write(tflite_quant_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwZkBxl456_5","executionInfo":{"status":"ok","timestamp":1651597779454,"user_tz":300,"elapsed":2122,"user":{"displayName":"Vilma Tirado Gómez","userId":"08135427317933817305"}},"outputId":"b2a46732-ce88-4ee3-d0d4-9e1bf992aa4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmp_tbtmb1l/assets\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["1480"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### No quantized\n"],"metadata":{"id":"tjMf1xhy5mRp"}},{"cell_type":"code","source":["# Convert the model to the TensorFlow Lite format without quantization\n","converter = tf.lite.TFLiteConverter.from_keras_model(split1_model)\n","model_no_quant_tflite = converter.convert()\n","\n","# Save the model to disk\n","open(\"converted_model_split1_noquant.tflite\", \"wb\").write(model_no_quant_tflite)\n","\n","# Convert the model to the TensorFlow Lite format with quantization\n","def representative_dataset():\n","  for i in range(500):\n","    yield([x_train[i].reshape(1, 1)])\n","# Set the optimization flag.\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","# Enforce integer only quantization\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","converter.inference_input_type = tf.int8\n","converter.inference_output_type = tf.int8\n","# Provide a representative dataset to ensure we quantize correctly.\n","converter.representative_dataset = representative_dataset\n","model_tflite = converter.convert()\n","\n","# Save the model to disk\n","open(\"converted_model_split1.tflite\", \"wb\").write(model_tflite)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICx3Yt2q6dFa","executionInfo":{"status":"ok","timestamp":1651598186146,"user_tz":300,"elapsed":1144,"user":{"displayName":"Vilma Tirado Gómez","userId":"08135427317933817305"}},"outputId":"0d5dc14c-1ca6-444c-9b41-1ef4319f9475"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmpam2gcdhp/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmpam2gcdhp/assets\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmp3qgwhmfe/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmp3qgwhmfe/assets\n","/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["1152"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## To convert to C++\n","We can then run this command to convert the model to c code.\n","```\n","xxd -i converted_model.tflite > model_data.cc\n","```"],"metadata":{"id":"SYIxQSNz6KYi"}}]}